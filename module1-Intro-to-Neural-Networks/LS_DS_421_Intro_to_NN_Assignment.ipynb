{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: This is the layer which interacts with dataset directly and each features/column will be traeted as one node or input.this layer will receive the info from the dataset & will pass it to the netwrork.\n",
    "\n",
    "\n",
    "\n",
    "### Hidden Layer:Hidden layers are the layers which are inside the network & can't be interacted directly except through input layer.\n",
    "\n",
    "\n",
    "### Output Layer:This is last and final layer in the network which gives output in the form of a vector as a answer for the given problem.\n",
    "\n",
    "\n",
    "### Neuron:Neurons are the most basic unit of the neural network & signals will be passes from one neuron to other if the certain threshold is passed.\n",
    "\n",
    "\n",
    "### Weight:these are attached to each input nodes.These are used to minimize the error sum of squares.These are the impact on the current layer based on the previous layer.\n",
    "\n",
    "\n",
    "\n",
    "### Activation Function:Determines if a neuron should be activated based on their weight threshhold.On the basis of the activation function we will get to know whether the output is a classification problem or regression problem.As activation function pass the signal to the next layer.\n",
    "\n",
    "\n",
    "### Node Map:it's a visual diagram of the architecture or \"topology\" of our neural network.It shows the flow chart of the path from input to output.\n",
    "\n",
    "\n",
    "\n",
    "### Perceptron: These are the simplest kind of Neural network which takes inputs & gives outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### In neural network there are 3 layers.First information from a dataset will be received through the nodes of input layers (number of nodes as per number of columns or features) then through hidden layer which will be the inside of the neural network & information will be processed doing different calculations.The flow starts with the inputs and then goes through a activation function if the weight exceeds the threshhold and moves through to outputs. We want to ensure we use bias nodes since that helps fit the mdoel and can shift the activation function to the left or the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "# input & output arrays\n",
    "\n",
    "inputs = np.array(df[['x1','x2']])\n",
    "correct_outputs = []\n",
    "for y in df['y']:\n",
    "    correct_outputs.append([y])\n",
    "correct_outputs = np.array(correct_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function and its derivative for updating weights\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]]\n",
      "Correct Outputs [[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs:\",inputs)\n",
    "print(\"Correct Outputs\",correct_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights [[0.45915504]\n",
      " [0.62163281]]\n",
      "(array([[-0.0001081 ],\n",
      "       [ 0.00010809]]), array([[ 0.125     ],\n",
      "       [ 0.12500721],\n",
      "       [ 0.12499279],\n",
      "       [-0.125     ]]))\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Class constructor for Perceptron.\n",
    "        \n",
    "        make sure you use Perceptron.fit() before trying to get predictions\n",
    "        \"\"\"\n",
    "        self.inputs = None\n",
    "        self.correct_outputs = None\n",
    "    \n",
    "    def resolve(self, inputs, correct_outputs, iterations=10000):\n",
    "        \"\"\"\n",
    "        Fit this model to some data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs: 2d numpy array, in a [[row], [row], [row]] format\n",
    "        \n",
    "        correct_outputs: 2d numpy array, in a [[row], [row], [row]] format\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        2d numpy array\n",
    "            resulting weights for the data.\n",
    "            \n",
    "        2d numpy array\n",
    "            resulting output for the data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # generate some initial weights for the perceptron\n",
    "        weights = np.random.random((len(inputs[0]),1))\n",
    "        print(\"Weights\",weights)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            # get the dot product of the weighted sum of the inputs and weights\n",
    "            weighted_sum = np.dot(inputs, weights)\n",
    "            #print(\"Weighted Sum\",weighted_sum)\n",
    "\n",
    "            # get the sigmoid of the weighted sum\n",
    "            activated_output = sigmoid(weighted_sum)\n",
    "            #print(\"Activated Output\",activated_output)\n",
    "\n",
    "            # subtract the correct values by the activated outputs\n",
    "            error = correct_outputs - activated_output\n",
    "            #print(\"Error\",error)\n",
    "\n",
    "            # and from the errors, get the adjustments that need to be made\n",
    "            adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "            #print(\"Adjustments\",adjustments)\n",
    "\n",
    "            # and update the weights\n",
    "            weights += np.dot(inputs.T, adjustments)\n",
    "        \n",
    "        return weights, adjustments\n",
    "\n",
    "p = Perceptron()\n",
    "print(p.resolve(inputs, correct_outputs, iterations=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03355237 0.82762513 0.40262844 0.19572216 0.         0.18789327\n",
      "  0.00350622 0.27960308]\n",
      " [0.008424   0.71604034 0.55598426 0.24429612 0.         0.22407851\n",
      "  0.00295683 0.26114412]\n",
      " [0.04039768 0.92409698 0.32318146 0.         0.         0.11765825\n",
      "  0.00339341 0.16159073]\n",
      " [0.00661199 0.58846737 0.43639153 0.15207584 0.62152733 0.185797\n",
      "  0.0011042  0.13885185]\n",
      " [0.         0.5963863  0.17412739 0.15236146 0.73133502 0.18762226\n",
      "  0.00996009 0.14365509]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "# feats = list(diabetes)[:-1]\n",
    "\n",
    "# X = ...\n",
    "\n",
    "\n",
    "n = Normalizer()\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "X = diabetes[feats]\n",
    "Xn = n.fit_transform(X)\n",
    "y = np.array([[r] for r in diabetes['Outcome']])\n",
    "print(Xn[:5])\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 1 1 0]\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, niter = 10):\n",
    "        self.niter = niter\n",
    "        self.weights = None\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize Weights and errors\n",
    "        self.weights = np.zeros(1 + X.shape[1])\n",
    "        self.errors = []\n",
    "        for i in range(self.niter):\n",
    "            err = 0\n",
    "            # iterate through records\n",
    "            for xi, target in zip(X, y):\n",
    "                # update delta\n",
    "                delta_w = 0.01 * (target - self.predict(xi))\n",
    "                # update non-bias weights\n",
    "                self.weights[1:] += delta_w * xi\n",
    "                # update bias\n",
    "                self.weights[0] += delta_w\n",
    "                # update error\n",
    "                err += int(delta_w != 0.0)\n",
    "            # append errors onto errorlist\n",
    "            self.errors.append(err)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where((np.dot(X, self.weights[1:]) + self.weights[0]) >= 0.0, 1, 0)\n",
    "        \n",
    "p = Perceptron()\n",
    "p.fit(Xn, y)\n",
    "print(p.predict(Xn)[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NNF (Python3)",
   "language": "python",
   "name": "u4-s2-nnf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
